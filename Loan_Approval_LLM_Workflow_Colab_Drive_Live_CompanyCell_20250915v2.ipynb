{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesemansfield2/Finance_loan_approval_genai_llm/blob/main/Loan_Approval_LLM_Workflow_Colab_Drive_Live_CompanyCell_20250915v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3398cd",
      "metadata": {
        "id": "3e3398cd"
      },
      "source": [
        "\n",
        "# Loan Approval — LLM Workflow (Colab • Drive • Live Gemini • Company & Limit)\n",
        "\n",
        "**Last updated:** 2025-09-15 06:13\n",
        "\n",
        "Colab-first, synthetic-only pipeline:\n",
        "- Map Google Drive\n",
        "- Set `company_to_assess` in its own cell (Step **2a**)\n",
        "- Generate both **application-level** data and a **company profile** (debt/equity, profitability, credit score, lawsuit etc.)\n",
        "- Call **live Gemini 2.5 Flash** for per-app JSON and a **company-level narrative**\n",
        "- Limit how many applications are processed for speed/cost\n",
        "- Save to: `/content/drive/Shareddrives/1a_Finance_LoanAI/loan`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10eac65d",
      "metadata": {
        "id": "10eac65d"
      },
      "source": [
        "\n",
        "---\n",
        "## 0) Map Google Drive (run this first)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "196007ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "196007ea",
        "outputId": "f3a13373-1299-4701-9a9d-98762a4ae50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e3bd8a",
      "metadata": {
        "id": "b6e3bd8a"
      },
      "source": [
        "\n",
        "---\n",
        "## 1) Install deps & set API key (placeholders)\n",
        "\n",
        "Uncomment both lines to install and set your key.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ec5f0068",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5f0068",
        "outputId": "15d7aa0c-34bc-42ca-84fc-0308c8fef37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GEMINI_API_KEY=#[enter gemini api key]\n"
          ]
        }
      ],
      "source": [
        "%pip install -q google-generativeai pydantic>=2.5.0 pandas scikit-learn numpy jsonschema python-dotenv\n",
        "%env GEMINI_API_KEY=#[enter gemini api key]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1222a37",
      "metadata": {
        "id": "b1222a37"
      },
      "source": [
        "\n",
        "---\n",
        "## 2) Setup & Basic Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 2) Setup & Basic Configuration ====\n",
        "\n",
        "import os, time, json, uuid, random\n",
        "from typing import List, Optional, Literal, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from jsonschema import validate as json_validate, Draft202012Validator\n",
        "from jsonschema.exceptions import ValidationError as JSONSchemaError\n",
        "import google.generativeai as genai\n",
        "\n",
        "# --- Basic knobs (EDIT HERE if needed) ---\n",
        "N_SYNTHETIC: int = int(os.getenv(\"N_SYNTHETIC\", \"500\"))\n",
        "\n",
        "# Where results will be written (Drive is already mounted in Step 0)\n",
        "OUTPUTS_DIR = \"/content/drive/Shareddrives/1a_Finance_LoanAI/loan\"  # <<< EDIT PATH IF YOU WANT\n",
        "os.makedirs(OUTPUTS_DIR, exist_ok=True)\n",
        "\n",
        "# LLM config (API key is set in Step 1)\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
        "LLM_MODEL_NAME = os.getenv(\"LLM_MODEL_NAME\", \"gemini-2.5-flash\")     # <<< change model if desired\n",
        "\n",
        "# Feature policy (allowed inputs to the LLM/rules)\n",
        "APP_ID_COL = \"application_id\"\n",
        "ALLOWED_FEATURES = [\n",
        "    \"annual_income\", \"loan_amount\", \"interest_rate\", \"term_months\",\n",
        "    \"fico_score\", \"employment_years\", \"dti\", \"purpose\", \"state_code\",\n",
        "    \"num_open_accounts\", \"delinquencies_2y\", \"revol_util\"\n",
        "]\n",
        "CATEGORICALS = [\"purpose\", \"state_code\"]\n",
        "NUMERICS = [f for f in ALLOWED_FEATURES if f not in CATEGORICALS]\n",
        "\n",
        "# Rules thresholds (EDIT to match your underwriting policy)\n",
        "DTI_APPROVE_MAX      = float(os.getenv(\"DTI_APPROVE_MAX\", \"0.36\"))\n",
        "DTI_CONDITIONAL_MAX  = float(os.getenv(\"DTI_CONDITIONAL_MAX\", \"0.48\"))\n",
        "FICO_APPROVE_MIN     = int(os.getenv(\"FICO_APPROVE_MIN\", \"720\"))\n",
        "FICO_CONDITIONAL_MIN = int(os.getenv(\"FICO_CONDITIONAL_MIN\", \"660\"))\n",
        "\n",
        "# --- LLM retry & throttle (used in Step 6/7) ---\n",
        "# Increase THROTTLE_SECONDS if you see rate limits; increase retries for flakiness.\n",
        "MAX_LLM_RETRIES   = int(os.getenv(\"MAX_LLM_RETRIES\", \"1\"))\n",
        "BACKOFF_BASE_SEC  = float(os.getenv(\"BACKOFF_BASE_SEC\", \"1.5\"))\n",
        "BACKOFF_JITTER    = float(os.getenv(\"BACKOFF_JITTER\", \"0.25\"))\n",
        "THROTTLE_SECONDS  = float(os.getenv(\"THROTTLE_SECONDS\", \"0.0\"))\n",
        "\n",
        "# --- Per-call timeout + optional fallback (Step 6/7 use these) ---\n",
        "CALL_TIMEOUT_SEC   = float(os.getenv(\"CALL_TIMEOUT_SEC\", \"20\"))  # hard stop per LLM call\n",
        "FALLBACK_TO_SINGLE = True  # try single-item calls if a batch fails/times out\n",
        "\n",
        "# Tracing (set False to silence per-app LLM latency lines)\n",
        "TRACE_LOGS = True  # <<< toggle to False if you want quieter logs\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Configured.\")\n",
        "print(\"  Output folder:\", OUTPUTS_DIR)\n",
        "print(\"  N_SYNTHETIC:\", N_SYNTHETIC)\n",
        "print(\"  LLM model:\", LLM_MODEL_NAME)\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"  ⚠️  GEMINI_API_KEY not set yet; uncomment Step 1 to set it.\")\n",
        "print(\"  Note: set company_to_assess & MAX_APPS_PER_COMPANY in Step 2a.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwInxo02JgkJ",
        "outputId": "4f9ecc8d-3e7f-4af5-cc79-050d35659c72"
      },
      "id": "JwInxo02JgkJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured.\n",
            "  Output folder: /content/drive/Shareddrives/1a_Finance_LoanAI/loan\n",
            "  N_SYNTHETIC: 500\n",
            "  LLM model: gemini-2.5-flash\n",
            "  Note: set company_to_assess & MAX_APPS_PER_COMPANY in Step 2a.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ff689d8",
      "metadata": {
        "id": "3ff689d8"
      },
      "source": [
        "\n",
        "---\n",
        "## 2a) Set Company & Limit (EDIT HERE)\n",
        "\n",
        "Change the company key and the processing limit as needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89f6565f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89f6565f",
        "outputId": "e4980419-7ab0-4a5d-cbff-0eacf0679c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company_to_assess: COMP123\n",
            "MAX_APPS_PER_COMPANY: 5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "company_to_assess: str = \"COMP123\"   # <<< edit this\n",
        "MAX_APPS_PER_COMPANY: int = 5       # <<< cap how many applications to process for this company\n",
        "\n",
        "print(\"company_to_assess:\", company_to_assess)\n",
        "print(\"MAX_APPS_PER_COMPANY:\", MAX_APPS_PER_COMPANY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93935fae",
      "metadata": {
        "id": "93935fae"
      },
      "source": [
        "\n",
        "---\n",
        "## 3) Schema & Validation (Pydantic + JSON Schema)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1863f7e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1863f7e6",
        "outputId": "70ca0ecc-2593-452e-e639-33ef3445bec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schemas ready.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Application(BaseModel):\n",
        "    application_id: str\n",
        "    company_id: str\n",
        "    annual_income: float\n",
        "    loan_amount: float\n",
        "    interest_rate: Optional[float] = None\n",
        "    term_months: int\n",
        "    fico_score: int\n",
        "    employment_years: float\n",
        "    dti: float\n",
        "    purpose: str\n",
        "    state_code: str\n",
        "    num_open_accounts: Optional[int] = 0\n",
        "    delinquencies_2y: Optional[int] = 0\n",
        "    revol_util: Optional[float] = 0.0\n",
        "\n",
        "    @field_validator(\"dti\")\n",
        "    @classmethod\n",
        "    def dti_in_0_1(cls, v):\n",
        "        if not (0 <= v <= 1.0):\n",
        "            raise ValueError(\"DTI must be 0..1 fraction\")\n",
        "        return v\n",
        "\n",
        "    @field_validator(\"fico_score\")\n",
        "    @classmethod\n",
        "    def fico_range(cls, v):\n",
        "        if not (300 <= v <= 850):\n",
        "            raise ValueError(\"FICO must be in 300..850\")\n",
        "        return v\n",
        "\n",
        "class LLMDecision(BaseModel):\n",
        "    version: str = \"1.0\"\n",
        "    decision: Literal[\"approve\", \"conditional\", \"deny\"]\n",
        "    reasons: List[str]\n",
        "    missing_documents: List[str] = []\n",
        "    policy_citations: List[str] = []\n",
        "    risk_summary: str\n",
        "    risk_score_0_1: Optional[float] = Field(default=None, ge=0.0, le=1.0)\n",
        "    fair_lending_flags: List[str] = []\n",
        "\n",
        "class FinalDecision(BaseModel):\n",
        "    application_id: str\n",
        "    company_id: str\n",
        "    baseline_decision: Literal[\"approve\", \"conditional\", \"deny\"]\n",
        "    llm_decision: LLMDecision\n",
        "    combined_decision: Literal[\"approve\", \"conditional\", \"deny\"]\n",
        "    notes: str = \"\"\n",
        "\n",
        "# Company profile schema (for the narrative stage)\n",
        "class CompanyProfile(BaseModel):\n",
        "    company_id: str\n",
        "    company_name: str\n",
        "    debt_to_equity: float\n",
        "    profit_margin: float\n",
        "    roa: float\n",
        "    roe: float\n",
        "    credit_score: int\n",
        "    lawsuit_flag: bool\n",
        "    lawsuit_summary: Optional[str] = \"\"\n",
        "\n",
        "LLM_DECISION_JSON_SCHEMA: Dict[str, Any] = LLMDecision.model_json_schema()\n",
        "validator = Draft202012Validator(LLM_DECISION_JSON_SCHEMA)\n",
        "print(\"Schemas ready.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3d249f6",
      "metadata": {
        "id": "c3d249f6"
      },
      "source": [
        "\n",
        "---\n",
        "## 4) Synthetic Data + Company Profiles\n",
        "\n",
        "Generates:\n",
        "- Application-level rows with `company_id`\n",
        "- A **company profile** table with fields used in the narrative (D/E, profitability, credit score, lawsuit flag/summary)\n",
        "\n",
        "Ensures `company_to_assess` has coverage and a realistic profile. For **COMP123**, we set:\n",
        "- Debt-to-Equity ≈ **0.8**\n",
        "- Credit Score ≈ **750**\n",
        "- `lawsuit_flag=True` with a short summary (so the LLM can reference **Chunk 1**).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237e2613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "237e2613",
        "outputId": "36655573-c9e8-4fae-c026-5dd5b21d1158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 500 rows total.\n",
            "COMP123 applications selected: 5\n",
            "Company profile: {'company_id': 'COMP123', 'company_name': 'Example Corp', 'debt_to_equity': 0.8, 'profit_margin': 0.22, 'roa': 0.18, 'roe': 0.43, 'credit_score': 750, 'lawsuit_flag': True, 'lawsuit_summary': 'Patent infringement lawsuit filed against Example Corp; potential damages material; outcome pending; impact assessment ongoing.'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "US_STATE_ABBRS = [\n",
        "    \"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\n",
        "    \"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\n",
        "    \"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\"\n",
        "]\n",
        "PURPOSES = [\"debt_consolidation\",\"home_improvement\",\"major_purchase\",\"medical\",\"auto\",\"other\"]\n",
        "\n",
        "def amortized_payment(principal: float, annual_rate: float, term_months: int) -> float:\n",
        "    r = annual_rate / 12.0\n",
        "    if r <= 0:\n",
        "        return principal / max(term_months, 1)\n",
        "    denom = (1 - (1 + r)**(-term_months))\n",
        "    return principal * r / max(denom, 1e-9)\n",
        "\n",
        "def generate_synthetic_applications(n: int = 500, seed: int = 42, include_company: str = \"COMP123\") -> pd.DataFrame:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    incomes = np.exp(rng.normal(11.1, 0.55, size=n))\n",
        "    fico = np.clip(rng.normal(700, 60, size=n).round(), 580, 800).astype(int)\n",
        "\n",
        "    term_choices = np.array([36, 60, 72])\n",
        "    term_probs = np.array([0.25, 0.6, 0.15])\n",
        "    terms = rng.choice(term_choices, size=n, p=term_probs)\n",
        "\n",
        "    base_rate = 0.22 - (fico - 580) * (0.22 - 0.07) / (800 - 580)\n",
        "    interest_rates = np.clip(base_rate + rng.normal(0, 0.01, size=n), 0.05, 0.28)\n",
        "\n",
        "    loan_frac = rng.uniform(0.1, 0.6, size=n)\n",
        "    loan_amount = (incomes * loan_frac).round(2)\n",
        "\n",
        "    employment_years = np.clip(rng.poisson(6, size=n), 0, 40).astype(float)\n",
        "    revol_util = np.clip(rng.normal(0.45, 0.2, size=n), 0, 0.95)\n",
        "    num_open_accounts = rng.integers(2, 20, size=n)\n",
        "    delinq_2y = rng.binomial(3, 0.15, size=n)\n",
        "\n",
        "    purposes = rng.choice(PURPOSES, size=n)\n",
        "    states = rng.choice(US_STATE_ABBRS, size=n)\n",
        "\n",
        "    existing_obl_ratio = np.clip(rng.normal(0.18, 0.08, size=n), 0.05, 0.5)\n",
        "    existing_obl = incomes * existing_obl_ratio / 12.0\n",
        "\n",
        "    monthly_payment = np.array([amortized_payment(p, r, t) for p, r, t in zip(loan_amount, interest_rates, terms)])\n",
        "    monthly_income = incomes / 12.0\n",
        "    dti = (existing_obl + monthly_payment) / np.maximum(monthly_income, 1.0)\n",
        "    dti = np.clip(dti, 0, 0.9)\n",
        "\n",
        "    companies = [f\"COMP{i:03d}\" for i in range(100, 200)]\n",
        "    base_companies = rng.choice(companies, size=n)\n",
        "    force_k = max(20, n // 10)\n",
        "    base_companies[:force_k] = include_company\n",
        "    rng.shuffle(base_companies)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"application_id\": [f\"A{100000+i}\" for i in range(n)],\n",
        "        \"company_id\": base_companies,\n",
        "        \"annual_income\": incomes.round(2),\n",
        "        \"loan_amount\": loan_amount,\n",
        "        \"interest_rate\": interest_rates.round(4),\n",
        "        \"term_months\": terms,\n",
        "        \"fico_score\": fico,\n",
        "        \"employment_years\": employment_years,\n",
        "        \"dti\": dti.round(4),\n",
        "        \"purpose\": purposes,\n",
        "        \"state_code\": states,\n",
        "        \"num_open_accounts\": num_open_accounts,\n",
        "        \"delinquencies_2y\": delinq_2y,\n",
        "        \"revol_util\": revol_util.round(4)\n",
        "    })\n",
        "    return df\n",
        "\n",
        "def generate_company_profiles(apps: pd.DataFrame, seed: int = 42) -> pd.DataFrame:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    comps = sorted(apps[\"company_id\"].unique().tolist())\n",
        "    rows = []\n",
        "    for cid in comps:\n",
        "        # defaults\n",
        "        d2e = float(np.clip(rng.normal(0.6, 0.25), 0.1, 1.5))\n",
        "        pm  = float(np.clip(rng.normal(0.15, 0.08), 0.02, 0.45))\n",
        "        roa = float(np.clip(rng.normal(0.08, 0.05), 0.01, 0.25))\n",
        "        roe = float(np.clip(rng.normal(0.14, 0.1), 0.02, 0.45))\n",
        "        cs  = int(np.clip(int(rng.normal(720, 40)), 600, 800))\n",
        "        lawsuit_flag = bool(rng.random() < 0.08)\n",
        "        lawsuit_summary = \"No material litigation disclosed.\"\n",
        "\n",
        "        # special case: ensure the focus company matches your expected example\n",
        "        if cid == \"COMP123\":\n",
        "            d2e = 0.8\n",
        "            cs = 750\n",
        "            lawsuit_flag = True\n",
        "            lawsuit_summary = (\n",
        "                \"Patent infringement lawsuit filed against Example Corp; \"\n",
        "                \"potential damages material; outcome pending; impact assessment ongoing.\"\n",
        "            )\n",
        "            company_name = \"Example Corp\"\n",
        "        else:\n",
        "            company_name = f\"Company {cid[-3:]}\"\n",
        "\n",
        "        rows.append({\n",
        "            \"company_id\": cid,\n",
        "            \"company_name\": company_name,\n",
        "            \"debt_to_equity\": round(d2e, 2),\n",
        "            \"profit_margin\": round(pm, 2),\n",
        "            \"roa\": round(roa, 2),\n",
        "            \"roe\": round(roe, 2),\n",
        "            \"credit_score\": cs,\n",
        "            \"lawsuit_flag\": lawsuit_flag,\n",
        "            \"lawsuit_summary\": lawsuit_summary if lawsuit_flag else \"\"\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "apps_df = generate_synthetic_applications(N_SYNTHETIC, seed=42, include_company=company_to_assess)\n",
        "profiles_df = generate_company_profiles(apps_df, seed=42)\n",
        "\n",
        "company_df = apps_df.query(\"company_id == @company_to_assess\").copy()\n",
        "company_profile = profiles_df.loc[profiles_df[\"company_id\"] == company_to_assess].iloc[0].to_dict()\n",
        "\n",
        "# limit number of applications\n",
        "if MAX_APPS_PER_COMPANY and len(company_df) > MAX_APPS_PER_COMPANY:\n",
        "    company_df = company_df.sample(n=MAX_APPS_PER_COMPANY, random_state=42).sort_values(APP_ID_COL).reset_index(drop=True)\n",
        "\n",
        "print(f\"Generated {len(apps_df):,} rows total.\")\n",
        "print(f\"{company_to_assess} applications selected: {len(company_df):,}\")\n",
        "print(\"Company profile:\", company_profile)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad236f4a",
      "metadata": {
        "id": "ad236f4a"
      },
      "source": [
        "\n",
        "---\n",
        "## 5) Baseline Decision (Rules) — DTI + FICO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f154d13",
      "metadata": {
        "id": "1f154d13"
      },
      "outputs": [],
      "source": [
        "\n",
        "def baseline_rules_decision(row: pd.Series) -> str:\n",
        "    dti = float(row.get(\"dti\", 1.0))\n",
        "    fico = int(row.get(\"fico_score\", 300))\n",
        "    if dti <= DTI_APPROVE_MAX and fico >= FICO_APPROVE_MIN:\n",
        "        return \"approve\"\n",
        "    if dti <= DTI_CONDITIONAL_MAX and fico >= FICO_CONDITIONAL_MIN:\n",
        "        return \"conditional\"\n",
        "    return \"deny\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4606738e",
      "metadata": {
        "id": "4606738e"
      },
      "source": [
        "\n",
        "---\n",
        "## 6) LLM (Gemini 2.5 Flash) — Per-App Strict JSON Output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 6) LLM (Gemini 2.5 Flash) — Single & Batched JSON with HARD timeout (process-based) ====\n",
        "\n",
        "import multiprocessing as mp\n",
        "import json, time, random\n",
        "from typing import List\n",
        "from jsonschema import validate as json_validate\n",
        "from jsonschema.exceptions import ValidationError as JSONSchemaError\n",
        "\n",
        "# Uses these knobs from Step 2:\n",
        "#   GEMINI_API_KEY, LLM_MODEL_NAME\n",
        "#   MAX_LLM_RETRIES, BACKOFF_BASE_SEC, BACKOFF_JITTER, THROTTLE_SECONDS\n",
        "#   CALL_TIMEOUT_SEC\n",
        "# And these schemas/types from earlier cells:\n",
        "#   LLMDecision, LLM_DECISION_JSON_SCHEMA, APP_ID_COL, ALLOWED_FEATURES\n",
        "\n",
        "LLM_SYSTEM_POLICY = \"\"\"\n",
        "You are an assistant that helps loan officers evaluate consumer loan applications.\n",
        "Follow risk policy and fair lending guidelines:\n",
        "- Do NOT use protected attributes (race, religion, gender, age, marital status, etc.) or proxies.\n",
        "- Base your analysis ONLY on the fields provided.\n",
        "- Be concise, factual, and cite policy sections by name (e.g., \"UW-Policy-2.1 DTI Thresholds\").\n",
        "- Always produce VALID JSON that conforms to the provided schema.\n",
        "- If information is missing, identify specific documents needed.\n",
        "- If the case is marginal, prefer \"conditional\" with explicit conditions.\n",
        "\"\"\"\n",
        "\n",
        "def _prompt_single(row: pd.Series, company_id: str) -> str:\n",
        "    safe = {k: row.get(k) for k in [APP_ID_COL, \"company_id\"] + ALLOWED_FEATURES if k in row.index}\n",
        "    return f\"\"\"\n",
        "System policy:\n",
        "{LLM_SYSTEM_POLICY}\n",
        "\n",
        "Context:\n",
        "Company to assess: \"{company_id}\"\n",
        "\n",
        "Task:\n",
        "Given this loan application data as JSON:\n",
        "{json.dumps(safe, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Produce a STRICT JSON object matching this JSON Schema (no extra keys):\n",
        "{json.dumps(LLM_DECISION_JSON_SCHEMA, ensure_ascii=False)}\n",
        "\n",
        "Return ONLY the JSON (no prose).\n",
        "\"\"\"\n",
        "\n",
        "def _prompt_batch(rows: List[pd.Series], company_id: str) -> str:\n",
        "    items = [{k: r.get(k) for k in [APP_ID_COL, \"company_id\"] + ALLOWED_FEATURES if k in r.index} for r in rows]\n",
        "    return f\"\"\"\n",
        "System policy:\n",
        "{LLM_SYSTEM_POLICY}\n",
        "\n",
        "Context:\n",
        "Company to assess: \"{company_id}\"\n",
        "\n",
        "Task:\n",
        "For each application in the array below, return a JSON array where each element is:\n",
        "{{\n",
        "  \"application_id\": string,\n",
        "  \"decision\": \"approve\" | \"conditional\" | \"deny\",\n",
        "  \"reasons\": string[],\n",
        "  \"missing_documents\": string[],\n",
        "  \"policy_citations\": string[],\n",
        "  \"risk_summary\": string,\n",
        "  \"risk_score_0_1\": number | null,\n",
        "  \"fair_lending_flags\": string[]\n",
        "}}\n",
        "\n",
        "Applications (JSON array):\n",
        "{json.dumps(items, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Return ONLY the JSON array with one element per input, same order as the inputs.\n",
        "\"\"\"\n",
        "\n",
        "def _worker_generate(prompt: str, out_q: mp.Queue):\n",
        "    \"\"\"\n",
        "    Runs in a separate process so we can enforce a HARD timeout by terminating the process.\n",
        "    Re-creates the model inside the process (objects aren’t picklable across processes).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        model = genai.GenerativeModel(\n",
        "            LLM_MODEL_NAME,\n",
        "            generation_config={\n",
        "                \"temperature\": 0.2,\n",
        "                \"top_p\": 0.9,\n",
        "                \"response_mime_type\": \"application/json\",\n",
        "            },\n",
        "        )\n",
        "        resp = model.generate_content(prompt)\n",
        "        text = (getattr(resp, \"text\", \"\") or \"\").strip()\n",
        "        if text.startswith(\"```\"):\n",
        "            text = text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        out_q.put({\"ok\": True, \"text\": text})\n",
        "    except Exception as e:\n",
        "        out_q.put({\"ok\": False, \"err\": repr(e)})\n",
        "\n",
        "def _call_with_hard_timeout(prompt: str, timeout_sec: float) -> str:\n",
        "    \"\"\"\n",
        "    Start a process, wait up to timeout_sec. If it runs long, terminate and raise.\n",
        "    \"\"\"\n",
        "    ctx = mp.get_context(\"spawn\")  # safe in Colab\n",
        "    q = ctx.Queue()\n",
        "    p = ctx.Process(target=_worker_generate, args=(prompt, q))\n",
        "    p.start()\n",
        "    p.join(timeout_sec)\n",
        "    if p.is_alive():\n",
        "        p.terminate()\n",
        "        p.join(1)\n",
        "        raise RuntimeError(f\"LLM call exceeded {timeout_sec}s (hard timeout)\")\n",
        "    if not q.empty():\n",
        "        msg = q.get()\n",
        "        if msg.get(\"ok\"):\n",
        "            return msg.get(\"text\", \"\")\n",
        "        raise RuntimeError(f\"LLM error: {msg.get('err')}\")\n",
        "    raise RuntimeError(\"LLM returned no data\")\n",
        "\n",
        "def _should_retry(exc) -> bool:\n",
        "    s = str(exc).lower()\n",
        "    return any(k in s for k in [\"unavailable\", \"timeout\", \"timed out\", \"quota\", \"rate\", \"503\", \"502\", \"500\", \"429\"])\n",
        "\n",
        "def call_llm_and_validate(row: pd.Series, company_id: str) -> 'LLMDecision':\n",
        "    if THROTTLE_SECONDS:\n",
        "        time.sleep(THROTTLE_SECONDS)\n",
        "    prompt = _prompt_single(row, company_id)\n",
        "    attempt, last_err = 0, None\n",
        "    while attempt < MAX_LLM_RETRIES:\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            raw = _call_with_hard_timeout(prompt, CALL_TIMEOUT_SEC)\n",
        "            latency = time.time() - t0\n",
        "            data = json.loads(raw)\n",
        "            json_validate(instance=data, schema=LLM_DECISION_JSON_SCHEMA)\n",
        "            out = LLMDecision(**data)\n",
        "            if TRACE_LOGS:\n",
        "                print(f\"[TRACE] LLM latency={latency:.2f}s id={row.get(APP_ID_COL)} decision={out.decision}\", flush=True)\n",
        "            return out\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            attempt += 1\n",
        "            if attempt < MAX_LLM_RETRIES and _should_retry(e):\n",
        "                backoff = (BACKOFF_BASE_SEC ** attempt) + random.uniform(0, BACKOFF_JITTER)\n",
        "                if TRACE_LOGS:\n",
        "                    print(f\"[TRACE] retry {attempt}/{MAX_LLM_RETRIES} in {backoff:.2f}s after error: {e}\", flush=True)\n",
        "                time.sleep(backoff)\n",
        "                continue\n",
        "            break\n",
        "    raise RuntimeError(f\"LLM failed after {MAX_LLM_RETRIES} attempts: {last_err}\")\n",
        "\n",
        "def call_llm_batch_and_validate(rows: List[pd.Series], company_id: str) -> dict[str, LLMDecision]:\n",
        "    if THROTTLE_SECONDS:\n",
        "        time.sleep(THROTTLE_SECONDS)\n",
        "    prompt = _prompt_batch(rows, company_id)\n",
        "    attempt, last_err = 0, None\n",
        "    while attempt < MAX_LLM_RETRIES:\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            raw = _call_with_hard_timeout(prompt, CALL_TIMEOUT_SEC)\n",
        "            latency = time.time() - t0\n",
        "            data = json.loads(raw)\n",
        "            if not isinstance(data, list):\n",
        "                raise RuntimeError(\"Expected JSON array from LLM.\")\n",
        "            results: dict[str, LLMDecision] = {}\n",
        "            for obj, r in zip(data, rows):\n",
        "                json_validate(instance=obj, schema=LLM_DECISION_JSON_SCHEMA)\n",
        "                dec = LLMDecision(**obj)\n",
        "                results[str(obj.get(\"application_id\", r.get(APP_ID_COL)))] = dec\n",
        "            if TRACE_LOGS:\n",
        "                print(f\"[TRACE] LLM batch latency={latency:.2f}s size={len(rows)}\", flush=True)\n",
        "            return results\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            attempt += 1\n",
        "            if attempt < MAX_LLM_RETRIES and _should_retry(e):\n",
        "                backoff = (BACKOFF_BASE_SEC ** attempt) + random.uniform(0, BACKOFF_JITTER)\n",
        "                if TRACE_LOGS:\n",
        "                    print(f\"[TRACE] batch retry {attempt}/{MAX_LLM_RETRIES} in {backoff:.2f}s after error: {e}\", flush=True)\n",
        "                time.sleep(backoff)\n",
        "                continue\n",
        "            break\n",
        "    raise RuntimeError(f\"LLM batch failed after {MAX_LLM_RETRIES} attempts: {last_err}\")\n"
      ],
      "metadata": {
        "id": "2ILqFXNiKz3g"
      },
      "id": "2ILqFXNiKz3g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "74062205",
      "metadata": {
        "id": "74062205"
      },
      "source": [
        "\n",
        "---\n",
        "## 7) Orchestrator + Batch (Limited by MAX_APPS_PER_COMPANY)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 7) Orchestrator + Batch (LLM triage + cache + time budget + progress) ====\n",
        "\n",
        "import math, time, json, os\n",
        "\n",
        "# ---- knobs you can tweak quickly ----\n",
        "BATCH_SIZE_APPS   = 4            # apps per Gemini request (try 4–10)\n",
        "TIME_BUDGET_SEC   = 30          # stop after ~N seconds (saves partials)\n",
        "CACHE_BASENAME    = f\"llm_cache_{company_to_assess}.json\"  # cache per company\n",
        "CACHE_PATH        = os.path.join(OUTPUTS_DIR, CACHE_BASENAME)\n",
        "\n",
        "def conservative_combine(baseline: str, llm_decision: LLMDecision) -> str:\n",
        "    order = {\"deny\": 2, \"conditional\": 1, \"approve\": 0}\n",
        "    return max(baseline, llm_decision.decision, key=lambda d: order[d])\n",
        "\n",
        "def needs_llm(row: pd.Series) -> bool:\n",
        "    \"\"\"Only call LLM for borderline cases to cut calls.\"\"\"\n",
        "    dti  = float(row.get(\"dti\", 1.0))\n",
        "    fico = int(row.get(\"fico_score\", 300))\n",
        "    clear_approve = (dti <= max(0.0, DTI_APPROVE_MAX - 0.05)) and (fico >= FICO_APPROVE_MIN + 20)\n",
        "    clear_deny    = (dti >= DTI_CONDITIONAL_MAX + 0.05) or (fico <= max(300, FICO_CONDITIONAL_MIN - 40))\n",
        "    return not (clear_approve or clear_deny)\n",
        "\n",
        "# ---- tiny JSON cache helpers ----\n",
        "def _load_cache(path: str) -> dict:\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {}\n",
        "\n",
        "def _save_cache(path: str, data: dict):\n",
        "    tmp = path + \".tmp\"\n",
        "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "def run_batch_decisions(apps: pd.DataFrame, company_id: str) -> pd.DataFrame:\n",
        "    if apps.empty:\n",
        "        raise ValueError(f\"No applications for {company_id}.\")\n",
        "\n",
        "    print(f\"[INFO] preparing {len(apps)} applications for company {company_id}...\", flush=True)\n",
        "    borderline_rows, clear_rows = [], []\n",
        "    for _, r in apps.iterrows():\n",
        "        (borderline_rows if needs_llm(r) else clear_rows).append(r)\n",
        "\n",
        "    print(f\"[INFO] clear cases (no LLM): {len(clear_rows)}\", flush=True)\n",
        "    print(f\"[INFO] borderline apps (LLM): {len(borderline_rows)}, batch size: {BATCH_SIZE_APPS}\", flush=True)\n",
        "\n",
        "    # Load cache; cache maps application_id -> LLMDecision dict\n",
        "    cache = _load_cache(CACHE_PATH)\n",
        "    print(f\"[INFO] loaded cache entries: {len(cache)} from {CACHE_PATH}\", flush=True)\n",
        "\n",
        "    # Split borderline into \"already cached\" vs \"needs call\"\n",
        "    to_call = []\n",
        "    cached_rows = []\n",
        "    for r in borderline_rows:\n",
        "        aid = str(r[APP_ID_COL])\n",
        "        if aid in cache:\n",
        "            cached_rows.append(r)\n",
        "        else:\n",
        "            to_call.append(r)\n",
        "\n",
        "    print(f\"[INFO] borderline cached: {len(cached_rows)}  |  to call: {len(to_call)}\", flush=True)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 1) Process clear ones (no LLM call)\n",
        "    if clear_rows:\n",
        "        print(f\"[INFO] processing clear cases...\", flush=True)\n",
        "    for idx, r in enumerate(clear_rows, start=1):\n",
        "        base = baseline_rules_decision(r)\n",
        "        llm = LLMDecision(\n",
        "            decision=base,\n",
        "            reasons=[\"Baseline strong enough: outside borderline region for DTI/FICO.\"],\n",
        "            missing_documents=[],\n",
        "            policy_citations=[\"UW-Policy-2.1 DTI Thresholds\", \"UW-Policy-3.4 FICO Bands\"],\n",
        "            risk_summary=\"Clear case per baseline thresholds; LLM not invoked.\",\n",
        "            fair_lending_flags=[]\n",
        "        )\n",
        "        combined = conservative_combine(base, llm)\n",
        "        results.append({\n",
        "            APP_ID_COL: str(r[APP_ID_COL]),\n",
        "            \"company_id\": str(r[\"company_id\"]),\n",
        "            \"baseline_decision\": base,\n",
        "            \"llm_decision\": llm.decision,\n",
        "            \"combined_decision\": combined,\n",
        "            \"reasons\": json.dumps(llm.reasons, ensure_ascii=False),\n",
        "            \"missing_documents\": json.dumps(llm.missing_documents, ensure_ascii=False),\n",
        "            \"policy_citations\": json.dumps(llm.policy_citations, ensure_ascii=False),\n",
        "            \"risk_summary\": llm.risk_summary,\n",
        "            \"risk_score_0_1\": llm.risk_score_0_1 if llm.risk_score_0_1 is not None else \"\",\n",
        "            \"fair_lending_flags\": json.dumps(llm.fair_lending_flags, ensure_ascii=False),\n",
        "            \"notes\": \"\"\n",
        "        })\n",
        "        if idx % 25 == 0 or idx == len(clear_rows):\n",
        "            print(f\"[INFO] clear processed: {idx}/{len(clear_rows)}\", flush=True)\n",
        "\n",
        "    # 2) Process cached borderline (fast)\n",
        "    if cached_rows:\n",
        "        print(f\"[INFO] materializing {len(cached_rows)} cached borderline decisions...\", flush=True)\n",
        "    for idx, r in enumerate(cached_rows, start=1):\n",
        "        aid = str(r[APP_ID_COL])\n",
        "        base = baseline_rules_decision(r)\n",
        "        d = cache.get(aid, {})\n",
        "        # Validate cache payload defensively\n",
        "        try:\n",
        "            json_validate(instance=d, schema=LLM_DECISION_JSON_SCHEMA)\n",
        "            llm = LLMDecision(**d)\n",
        "        except Exception:\n",
        "            llm = LLMDecision(\n",
        "                decision=base,\n",
        "                reasons=[\"Cache invalid; baseline applied.\"],\n",
        "                missing_documents=[],\n",
        "                policy_citations=[\"System-Fallback-1.0\"],\n",
        "                risk_summary=\"Cache invalid; baseline applied.\",\n",
        "                fair_lending_flags=[]\n",
        "            )\n",
        "        combined = conservative_combine(base, llm)\n",
        "        results.append({\n",
        "            APP_ID_COL: aid,\n",
        "            \"company_id\": str(r[\"company_id\"]),\n",
        "            \"baseline_decision\": base,\n",
        "            \"llm_decision\": llm.decision,\n",
        "            \"combined_decision\": combined,\n",
        "            \"reasons\": json.dumps(llm.reasons, ensure_ascii=False),\n",
        "            \"missing_documents\": json.dumps(llm.missing_documents, ensure_ascii=False),\n",
        "            \"policy_citations\": json.dumps(llm.policy_citations, ensure_ascii=False),\n",
        "            \"risk_summary\": llm.risk_summary,\n",
        "            \"risk_score_0_1\": llm.risk_score_0_1 if llm.risk_score_0_1 is not None else \"\",\n",
        "            \"fair_lending_flags\": json.dumps(llm.fair_lending_flags, ensure_ascii=False),\n",
        "            \"notes\": \"\"\n",
        "        })\n",
        "        if idx % 25 == 0 or idx == len(cached_rows):\n",
        "            print(f\"[INFO] cached processed: {idx}/{len(cached_rows)}\", flush=True)\n",
        "\n",
        "    # 3) Process remaining borderline in mini-batches (LLM), with time budget + incremental save\n",
        "    start = time.time()\n",
        "    total_call = len(to_call)\n",
        "    if total_call:\n",
        "        total_batches = math.ceil(total_call / BATCH_SIZE_APPS)\n",
        "        print(f\"[INFO] calling LLM for {total_call} borderline apps in {total_batches} batch(es)...\", flush=True)\n",
        "\n",
        "    for i in range(0, total_call, BATCH_SIZE_APPS):\n",
        "        # Time budget check (between batches)\n",
        "        elapsed = time.time() - start\n",
        "        if elapsed > TIME_BUDGET_SEC:\n",
        "            print(f\"[WARN] time budget ({TIME_BUDGET_SEC}s) reached — stopping further LLM calls.\", flush=True)\n",
        "            break\n",
        "\n",
        "        batch = to_call[i:i+BATCH_SIZE_APPS]\n",
        "        batch_idx = (i // BATCH_SIZE_APPS) + 1\n",
        "        print(f\"[INFO] batch {batch_idx}/{total_batches}: {len(batch)} app(s)\", flush=True)\n",
        "\n",
        "        try:\n",
        "            decisions_map = call_llm_batch_and_validate(batch, company_id)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] batch {batch_idx} failed ({e})\", flush=True)\n",
        "            if FALLBACK_TO_SINGLE:\n",
        "                print(f\"[INFO] falling back to single-item calls for this batch...\", flush=True)\n",
        "                decisions_map = {}\n",
        "                for r in batch:\n",
        "                    aid = str(r[APP_ID_COL])\n",
        "                    try:\n",
        "                        decisions_map[aid] = call_llm_and_validate(r, company_id)\n",
        "                    except Exception as ee:\n",
        "                        print(f\"[WARN] single call failed for {aid} ({ee}); will use baseline.\", flush=True)\n",
        "            else:\n",
        "                print(f\"[INFO] falling back to baseline for entire batch.\", flush=True)\n",
        "                decisions_map = {}\n",
        "\n",
        "        # append results; update cache; incremental save\n",
        "        for r in batch:\n",
        "            app_id = str(r[APP_ID_COL])\n",
        "            base = baseline_rules_decision(r)\n",
        "            llm = decisions_map.get(app_id)\n",
        "            if llm:\n",
        "                # store in cache\n",
        "                cache[app_id] = llm.model_dump()\n",
        "            else:\n",
        "                llm = LLMDecision(\n",
        "                    decision=base,\n",
        "                    reasons=[\"LLM unavailable/failure for this app; baseline applied.\"],\n",
        "                    missing_documents=[],\n",
        "                    policy_citations=[\"System-Fallback-1.0\"],\n",
        "                    risk_summary=\"LLM call failed; baseline applied.\",\n",
        "                    fair_lending_flags=[]\n",
        "                )\n",
        "            combined = conservative_combine(base, llm)\n",
        "            results.append({\n",
        "                APP_ID_COL: app_id,\n",
        "                \"company_id\": str(r[\"company_id\"]),\n",
        "                \"baseline_decision\": base,\n",
        "                \"llm_decision\": llm.decision,\n",
        "                \"combined_decision\": combined,\n",
        "                \"reasons\": json.dumps(llm.reasons, ensure_ascii=False),\n",
        "                \"missing_documents\": json.dumps(llm.missing_documents, ensure_ascii=False),\n",
        "                \"policy_citations\": json.dumps(llm.policy_citations, ensure_ascii=False),\n",
        "                \"risk_summary\": llm.risk_summary,\n",
        "                \"risk_score_0_1\": llm.risk_score_0_1 if llm.risk_score_0_1 is not None else \"\",\n",
        "                \"fair_lending_flags\": json.dumps(llm.fair_lending_flags, ensure_ascii=False),\n",
        "                \"notes\": \"\" if llm.decision == base else \"Conservative merge of baseline+LLM; review if disagreement.\"\n",
        "            })\n",
        "\n",
        "        # save cache + partial CSV after each batch\n",
        "        _save_cache(CACHE_PATH, cache)\n",
        "        partial_csv = os.path.join(OUTPUTS_DIR, f\"loan_llm_decisions_{company_id}_partial.csv\")\n",
        "        pd.DataFrame(results).sort_values(APP_ID_COL).to_csv(partial_csv, index=False)\n",
        "        print(f\"[INFO] completed batch {batch_idx}/{total_batches}  |  partial saved → {partial_csv}\", flush=True)\n",
        "\n",
        "    # Final dataframe\n",
        "    df = pd.DataFrame(results).sort_values(APP_ID_COL).reset_index(drop=True)\n",
        "    print(f\"[INFO] completed {len(df)} decision rows. Cache entries now: {len(cache)}\", flush=True)\n",
        "    return df\n",
        "\n",
        "# Run with caching + time budget\n",
        "decisions_df = run_batch_decisions(company_df, company_to_assess)\n",
        "out_csv = os.path.join(OUTPUTS_DIR, f\"loan_llm_decisions_{company_to_assess}.csv\")\n",
        "decisions_df.to_csv(out_csv, index=False)\n",
        "print(f\"[INFO] saved {len(decisions_df)} decisions -> {out_csv}\", flush=True)\n",
        "\n",
        "# Preview\n",
        "decisions_df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "CLW-UGddJ0cH",
        "outputId": "67f07e96-a1a8-4cd5-807c-24c5b09f1ec7"
      },
      "id": "CLW-UGddJ0cH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] preparing 5 applications for company COMP123...\n",
            "[INFO] clear cases (no LLM): 1\n",
            "[INFO] borderline apps (LLM): 4, batch size: 4\n",
            "[INFO] loaded cache entries: 0 from /content/drive/Shareddrives/1a_Finance_LoanAI/loan/llm_cache_COMP123.json\n",
            "[INFO] borderline cached: 0  |  to call: 4\n",
            "[INFO] processing clear cases...\n",
            "[INFO] clear processed: 1/1\n",
            "[INFO] calling LLM for 4 borderline apps in 1 batch(es)...\n",
            "[INFO] batch 1/1: 4 app(s)\n",
            "[WARN] batch 1 failed (LLM batch failed after 1 attempts: LLM returned no data)\n",
            "[INFO] falling back to single-item calls for this batch...\n",
            "[WARN] single call failed for A100110 (LLM failed after 1 attempts: LLM returned no data); will use baseline.\n",
            "[WARN] single call failed for A100211 (LLM failed after 1 attempts: LLM returned no data); will use baseline.\n",
            "[WARN] single call failed for A100439 (LLM failed after 1 attempts: LLM returned no data); will use baseline.\n",
            "[WARN] single call failed for A100473 (LLM failed after 1 attempts: LLM returned no data); will use baseline.\n",
            "[INFO] completed batch 1/1  |  partial saved → /content/drive/Shareddrives/1a_Finance_LoanAI/loan/loan_llm_decisions_COMP123_partial.csv\n",
            "[INFO] completed 5 decision rows. Cache entries now: 0\n",
            "[INFO] saved 5 decisions -> /content/drive/Shareddrives/1a_Finance_LoanAI/loan/loan_llm_decisions_COMP123.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  application_id company_id baseline_decision llm_decision combined_decision  \\\n",
              "0        A100110    COMP123              deny         deny              deny   \n",
              "1        A100211    COMP123           approve      approve           approve   \n",
              "2        A100439    COMP123           approve      approve           approve   \n",
              "3        A100450    COMP123              deny         deny              deny   \n",
              "4        A100473    COMP123           approve      approve           approve   \n",
              "\n",
              "                                             reasons missing_documents  \\\n",
              "0  [\"LLM unavailable/failure for this app; baseli...                []   \n",
              "1  [\"LLM unavailable/failure for this app; baseli...                []   \n",
              "2  [\"LLM unavailable/failure for this app; baseli...                []   \n",
              "3  [\"Baseline strong enough: outside borderline r...                []   \n",
              "4  [\"LLM unavailable/failure for this app; baseli...                []   \n",
              "\n",
              "                                    policy_citations  \\\n",
              "0                            [\"System-Fallback-1.0\"]   \n",
              "1                            [\"System-Fallback-1.0\"]   \n",
              "2                            [\"System-Fallback-1.0\"]   \n",
              "3  [\"UW-Policy-2.1 DTI Thresholds\", \"UW-Policy-3....   \n",
              "4                            [\"System-Fallback-1.0\"]   \n",
              "\n",
              "                                        risk_summary risk_score_0_1  \\\n",
              "0                 LLM call failed; baseline applied.                  \n",
              "1                 LLM call failed; baseline applied.                  \n",
              "2                 LLM call failed; baseline applied.                  \n",
              "3  Clear case per baseline thresholds; LLM not in...                  \n",
              "4                 LLM call failed; baseline applied.                  \n",
              "\n",
              "  fair_lending_flags notes  \n",
              "0                 []        \n",
              "1                 []        \n",
              "2                 []        \n",
              "3                 []        \n",
              "4                 []        "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-418ccee1-d0ba-46fe-bd9a-178a6eafd69d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application_id</th>\n",
              "      <th>company_id</th>\n",
              "      <th>baseline_decision</th>\n",
              "      <th>llm_decision</th>\n",
              "      <th>combined_decision</th>\n",
              "      <th>reasons</th>\n",
              "      <th>missing_documents</th>\n",
              "      <th>policy_citations</th>\n",
              "      <th>risk_summary</th>\n",
              "      <th>risk_score_0_1</th>\n",
              "      <th>fair_lending_flags</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A100110</td>\n",
              "      <td>COMP123</td>\n",
              "      <td>deny</td>\n",
              "      <td>deny</td>\n",
              "      <td>deny</td>\n",
              "      <td>[\"LLM unavailable/failure for this app; baseli...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"System-Fallback-1.0\"]</td>\n",
              "      <td>LLM call failed; baseline applied.</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A100211</td>\n",
              "      <td>COMP123</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>[\"LLM unavailable/failure for this app; baseli...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"System-Fallback-1.0\"]</td>\n",
              "      <td>LLM call failed; baseline applied.</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A100439</td>\n",
              "      <td>COMP123</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>[\"LLM unavailable/failure for this app; baseli...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"System-Fallback-1.0\"]</td>\n",
              "      <td>LLM call failed; baseline applied.</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A100450</td>\n",
              "      <td>COMP123</td>\n",
              "      <td>deny</td>\n",
              "      <td>deny</td>\n",
              "      <td>deny</td>\n",
              "      <td>[\"Baseline strong enough: outside borderline r...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"UW-Policy-2.1 DTI Thresholds\", \"UW-Policy-3....</td>\n",
              "      <td>Clear case per baseline thresholds; LLM not in...</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A100473</td>\n",
              "      <td>COMP123</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>approve</td>\n",
              "      <td>[\"LLM unavailable/failure for this app; baseli...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[\"System-Fallback-1.0\"]</td>\n",
              "      <td>LLM call failed; baseline applied.</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-418ccee1-d0ba-46fe-bd9a-178a6eafd69d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-418ccee1-d0ba-46fe-bd9a-178a6eafd69d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-418ccee1-d0ba-46fe-bd9a-178a6eafd69d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1ce56a54-ec75-4201-9de2-e9a42559bcff\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ce56a54-ec75-4201-9de2-e9a42559bcff')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1ce56a54-ec75-4201-9de2-e9a42559bcff button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "decisions_df",
              "summary": "{\n  \"name\": \"decisions_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"application_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A100211\",\n          \"A100473\",\n          \"A100439\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"COMP123\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"baseline_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"approve\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"approve\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_decision\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"approve\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reasons\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[\\\"Baseline strong enough: outside borderline region for DTI/FICO.\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"missing_documents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"policy_citations\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"[\\\"UW-Policy-2.1 DTI Thresholds\\\", \\\"UW-Policy-3.4 FICO Bands\\\"]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_summary\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Clear case per baseline thresholds; LLM not invoked.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk_score_0_1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fair_lending_flags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"[]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4d312c",
      "metadata": {
        "id": "be4d312c"
      },
      "source": [
        "\n",
        "---\n",
        "## 8) Company-Level Narrative (Live LLM) — Matches Your Expected Structure\n",
        "\n",
        "Produces a Markdown report like your example, referencing **lawsuit**, **debt-to-equity**, **credit score**, etc.  \n",
        "It uses the **company profile** plus a small set of representative \"chunks\" that the model can cite.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 8) Company-Level Narrative (Live LLM with HARD timeout + retries + fallback) ====\n",
        "\n",
        "import json, time, os, random\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Knobs (inherits CALL_TIMEOUT_SEC/BACKOFF_* from Step 2 / Step 6)\n",
        "SUMMARY_TIMEOUT_SEC = float(os.getenv(\"SUMMARY_TIMEOUT_SEC\", str(CALL_TIMEOUT_SEC)))  # per-call hard timeout\n",
        "SUMMARY_RETRIES     = int(os.getenv(\"SUMMARY_RETRIES\", \"1\"))  # extra attempts beyond the first\n",
        "GENERATE_SUMMARY    = True  # set False to always use fallback narrative\n",
        "\n",
        "def _make_company_chunks(profile: Dict[str, Any]) -> list[Dict[str, str]]:\n",
        "    chunks = []\n",
        "    if profile.get(\"lawsuit_flag\"):\n",
        "        chunks.append({\"id\": \"Chunk 1\", \"text\": profile.get(\"lawsuit_summary\", \"\")})\n",
        "    chunks.append({\n",
        "        \"id\": \"Financial Ratios\",\n",
        "        \"text\": (\n",
        "            f\"Debt-to-Equity: {profile['debt_to_equity']}; \"\n",
        "            f\"Profit Margin: {profile['profit_margin']}; \"\n",
        "            f\"ROA: {profile['roa']}; ROE: {profile['roe']}.\"\n",
        "        )\n",
        "    })\n",
        "    chunks.append({\"id\": \"Credit\", \"text\": f\"Experian credit score: {profile['credit_score']}.\"})\n",
        "    return chunks\n",
        "\n",
        "def _build_summary_prompt(profile: Dict[str, Any], decisions_df: pd.DataFrame) -> str:\n",
        "    company_name = profile.get(\"company_name\", profile[\"company_id\"])\n",
        "    chunks = _make_company_chunks(profile)\n",
        "    sample = decisions_df[[APP_ID_COL, \"combined_decision\", \"risk_summary\"]].head(10).to_dict(orient=\"records\")\n",
        "\n",
        "    return f\"\"\"\n",
        "System policy:\n",
        "{LLM_SYSTEM_POLICY}\n",
        "\n",
        "You are a senior credit underwriter. Create a concise Markdown report with the **exact** structure below.\n",
        "Use the provided company profile metrics and context chunks. Keep the tone professional and specific.\n",
        "If a lawsuit chunk exists, reference it as **Chunk 1** in Supporting Evidence.\n",
        "\n",
        "Company: {company_name}\n",
        "Company Key: {profile['company_id']}\n",
        "\n",
        "Company Profile (JSON):\n",
        "{json.dumps(profile, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Context Chunks (JSON):\n",
        "{json.dumps(chunks, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Recent Sample Decisions (JSON, first 10 max):\n",
        "{json.dumps(sample, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Please output **only** the following Markdown (no preface, no afterword):\n",
        "\n",
        "Assessing loan risk for company: {profile['company_id']}...\n",
        "\n",
        "--- Final Loan Risk Assessment and Recommendation ---\n",
        "- **Key Risk Factors:**\n",
        "    * **Lawsuit:** [If lawsuit_flag true, summarize the risk and uncertainty in 1–2 sentences. Otherwise omit this bullet.]\n",
        "    * **Debt-to-Equity Ratio:** Explain what the value ({profile['debt_to_equity']}) means for leverage and resilience.\n",
        "    * [Optionally include one more risk factor derived from ratios or credit score if warranted.]\n",
        "\n",
        "- **Supporting Evidence:**\n",
        "\n",
        "    * **Chunk 1:** [If a lawsuit chunk exists, cite its substance succinctly.]\n",
        "    * **Financial Ratios:** Reflect Profit Margin ({profile['profit_margin']}), ROA ({profile['roa']}), ROE ({profile['roe']}).\n",
        "    * **Credit Score:** Note the score ({profile['credit_score']}) and how it interacts with other risks.\n",
        "\n",
        "- **Overall Risk Assessment:** [Low | Medium | High]\n",
        "\n",
        "- **Loan Recommendation:** [Approve | Conditional / Further Review | Deny]\n",
        "\n",
        "- **Justification:**\n",
        "\n",
        "[Write 6–10 sentences covering strengths, risks, and specific next steps (e.g., legal review, scenario modeling, sensitivity analysis).]\n",
        "\"\"\"\n",
        "\n",
        "def _fallback_company_narrative(profile: Dict[str, Any], decisions_df: pd.DataFrame) -> str:\n",
        "    # Deterministic, local-only narrative that mirrors your expected format\n",
        "    company_key = profile[\"company_id\"]\n",
        "    lawsuit_bullet = \"\"\n",
        "    evidence_chunk1 = \"\"\n",
        "    if profile.get(\"lawsuit_flag\"):\n",
        "        lawsuit_bullet = (\n",
        "            \"    * **Lawsuit:** \" +\n",
        "            (profile.get(\"lawsuit_summary\") or \"Pending litigation; outcome and financial impact uncertain.\") +\n",
        "            \"\\n\"\n",
        "        )\n",
        "        evidence_chunk1 = f\"    * **Chunk 1:** {profile.get('lawsuit_summary', 'Pending litigation details.')}\"\n",
        "\n",
        "    # Simple risk heuristic for fallback\n",
        "    d2e = float(profile[\"debt_to_equity\"])\n",
        "    credit = int(profile[\"credit_score\"])\n",
        "    risk_level = \"Medium\"\n",
        "    if d2e >= 1.0 or credit < 680:\n",
        "        risk_level = \"High\"\n",
        "    elif d2e <= 0.4 and credit >= 760 and not profile.get(\"lawsuit_flag\"):\n",
        "        risk_level = \"Low\"\n",
        "\n",
        "    # Recommendation heuristic\n",
        "    recommendation = \"Further Review\" if profile.get(\"lawsuit_flag\") else (\"Approve\" if risk_level == \"Low\" else \"Conditional\")\n",
        "\n",
        "    return f\"\"\"Assessing loan risk for company: {company_key}...\n",
        "\n",
        "--- Final Loan Risk Assessment and Recommendation ---\n",
        "- **Key Risk Factors:**\n",
        "{lawsuit_bullet if lawsuit_bullet else \"\"}    * **Debt-to-Equity Ratio:** The current ratio of {d2e} indicates leverage that affects resilience to shocks.\n",
        "    * **Credit Profile:** Experian credit score of {credit} indicates {\"strong\" if credit>=740 else \"moderate\"} credit quality.\n",
        "\n",
        "- **Supporting Evidence:**\n",
        "\n",
        "{evidence_chunk1 if evidence_chunk1 else \"\"}    * **Financial Ratios:** Profit Margin {profile['profit_margin']}, ROA {profile['roa']}, ROE {profile['roe']}.\n",
        "    * **Credit Score:** {credit}.\n",
        "\n",
        "- **Overall Risk Assessment:** {risk_level}\n",
        "\n",
        "- **Loan Recommendation:** {recommendation}\n",
        "\n",
        "- **Justification:**\n",
        "\n",
        "The company's operating metrics indicate {\"solid\" if profile['profit_margin']>=0.1 else \"modest\"} profitability with ROA {profile['roa']} and ROE {profile['roe']}. Debt-to-Equity at {d2e} affects flexibility and increases sensitivity to revenue or margin compression. The credit score of {credit} supports access to credit on reasonable terms{\"; however, pending litigation adds uncertainty\" if profile.get(\"lawsuit_flag\") else \"\"}. We recommend {\"a focused legal review and scenario analysis under adverse outcomes, including liquidity impacts and covenant headroom, before finalizing terms\" if profile.get(\"lawsuit_flag\") else \"standard covenants and ongoing monitoring appropriate to the risk level\"}. Sensitivity analysis on cash flows under rate shocks and downside revenue cases is advised to validate repayment capacity.\"\"\"\n",
        "\n",
        "def generate_company_narrative_safe(profile: Dict[str, Any], decisions_df: pd.DataFrame) -> str:\n",
        "    if not GENERATE_SUMMARY:\n",
        "        print(\"[INFO] summary generation disabled; using fallback.\", flush=True)\n",
        "        return _fallback_company_narrative(profile, decisions_df)\n",
        "\n",
        "    prompt = _build_summary_prompt(profile, decisions_df)\n",
        "\n",
        "    attempt = 0\n",
        "    last_err = None\n",
        "    while attempt <= SUMMARY_RETRIES:\n",
        "        if THROTTLE_SECONDS:\n",
        "            time.sleep(THROTTLE_SECONDS)\n",
        "        try:\n",
        "            print(f\"[INFO] generating company narrative (attempt {attempt+1})...\", flush=True)\n",
        "            text = _call_with_hard_timeout(prompt, SUMMARY_TIMEOUT_SEC)  # from Step 6\n",
        "            text = (text or \"\").strip()\n",
        "            if not text:\n",
        "                raise RuntimeError(\"Empty narrative from LLM.\")\n",
        "            print(\"[INFO] narrative generated via LLM.\", flush=True)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if attempt < SUMMARY_RETRIES:\n",
        "                backoff = (BACKOFF_BASE_SEC ** (attempt+1)) + random.uniform(0, BACKOFF_JITTER)\n",
        "                print(f\"[WARN] narrative attempt {attempt+1} failed ({e}); retrying in {backoff:.2f}s...\", flush=True)\n",
        "                time.sleep(backoff)\n",
        "                attempt += 1\n",
        "            else:\n",
        "                print(f\"[WARN] narrative failed after {attempt+1} attempt(s): {e}. Using fallback.\", flush=True)\n",
        "                return _fallback_company_narrative(profile, decisions_df)\n",
        "\n",
        "# ---- Run and save the narrative ----\n",
        "print(\"[INFO] starting company-level narrative...\", flush=True)\n",
        "narrative_md = generate_company_narrative_safe(company_profile, decisions_df)\n",
        "narrative_path = os.path.join(OUTPUTS_DIR, f\"company_narrative_{company_to_assess}.md\")\n",
        "with open(narrative_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(narrative_md or \"(No narrative generated.)\")\n",
        "print(f\"[INFO] saved company narrative → {narrative_path}\", flush=True)\n",
        "print(narrative_md[:1000] + (\"...\" if len(narrative_md) > 1000 else \"\"), flush=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA04yfRCLa3A",
        "outputId": "8193951d-f256-48bf-987e-514985c357b6"
      },
      "id": "VA04yfRCLa3A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] starting company-level narrative...\n",
            "[INFO] generating company narrative (attempt 1)...\n",
            "[WARN] narrative attempt 1 failed (LLM returned no data); retrying in 1.66s...\n",
            "[INFO] generating company narrative (attempt 2)...\n",
            "[WARN] narrative failed after 2 attempt(s): LLM returned no data. Using fallback.\n",
            "[INFO] saved company narrative → /content/drive/Shareddrives/1a_Finance_LoanAI/loan/company_narrative_COMP123.md\n",
            "Assessing loan risk for company: COMP123...\n",
            "\n",
            "--- Final Loan Risk Assessment and Recommendation ---\n",
            "- **Key Risk Factors:**\n",
            "    * **Lawsuit:** Patent infringement lawsuit filed against Example Corp; potential damages material; outcome pending; impact assessment ongoing.\n",
            "    * **Debt-to-Equity Ratio:** The current ratio of 0.8 indicates leverage that affects resilience to shocks.\n",
            "    * **Credit Profile:** Experian credit score of 750 indicates strong credit quality.\n",
            "\n",
            "- **Supporting Evidence:**\n",
            "\n",
            "    * **Chunk 1:** Patent infringement lawsuit filed against Example Corp; potential damages material; outcome pending; impact assessment ongoing.    * **Financial Ratios:** Profit Margin 0.22, ROA 0.18, ROE 0.43.\n",
            "    * **Credit Score:** 750.\n",
            "\n",
            "- **Overall Risk Assessment:** Medium\n",
            "\n",
            "- **Loan Recommendation:** Further Review\n",
            "\n",
            "- **Justification:**\n",
            "\n",
            "The company's operating metrics indicate solid profitability with ROA 0.18 and ROE 0.43. Debt-to-Equity at 0.8 affects flexibility and increases sensitivi...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd984792",
      "metadata": {
        "id": "cd984792"
      },
      "source": [
        "\n",
        "---\n",
        "## 9) Guardrails\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e028ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e028ac",
        "outputId": "5a791a37-9a8a-49a5-9114-382e69d50436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRACE] Protected-attr check passed. Total rows: 500\n"
          ]
        }
      ],
      "source": [
        "\n",
        "PROTECTED_EXAMPLE = {\"race\", \"gender\", \"age\", \"religion\", \"marital_status\"}\n",
        "def assert_no_protected_columns(df: pd.DataFrame):\n",
        "    bad = PROTECTED_EXAMPLE.intersection(set(map(str.lower, df.columns)))\n",
        "    if bad:\n",
        "        raise ValueError(f\"Protected attributes detected in DataFrame: {sorted(bad)}. Remove before proceeding.\")\n",
        "assert_no_protected_columns(apps_df)\n",
        "print(\"[TRACE] Protected-attr check passed. Total rows:\", len(apps_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efe45f02",
      "metadata": {
        "id": "efe45f02"
      },
      "source": [
        "\n",
        "---\n",
        "## 10) (Optional) Silence Tracing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68fd4562",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68fd4562",
        "outputId": "befe0768-27c8-48ca-df66-8732ac3ab747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRACE_LOGS set to False\n"
          ]
        }
      ],
      "source": [
        "\n",
        "TRACE_LOGS = False\n",
        "print(\"TRACE_LOGS set to\", TRACE_LOGS)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}